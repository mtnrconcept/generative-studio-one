import type { GeneratedResult } from "@/types/result";
import type { GenerationPlan, PlanSection } from "@/types/plan";
import type { ImageAspectRatio, ImageGenerationSettings } from "@/types/image";
import { supabase } from "@/integrations/supabase/client";

export type CreativeTool = "image" | "music" | "agent" | "game";

interface GenerationOptions {
  prompt: string;
  version: number;
  modification?: string;
  previous?: GeneratedResult | null;
  imageSettings?: ImageGenerationSettings;
  plan?: GenerationPlan | null;
}

interface PlanOptions {
  image?: ImageGenerationSettings;
}

const TOOL_LABELS: Record<CreativeTool, string> = {
  image: "G√©n√©rateur d'image",
  music: "G√©n√©rateur de musique",
  agent: "G√©n√©rateur d'agents",
  game: "G√©n√©rateur de jeux vid√©o",
};

const simpleHash = (value: string) => {
  let hash = 0;
  for (let index = 0; index < value.length; index += 1) {
    hash = (hash << 5) - hash + value.charCodeAt(index);
    hash |= 0;
  }
  return Math.abs(hash);
};

const pick = <T>(items: T[], hash: number, offset: number) =>
  items[(hash + offset) % items.length];

const detectKeyword = (
  prompt: string,
  mapping: Array<[RegExp, string]>,
  fallback: string,
) => {
  const lowered = prompt.toLowerCase();
  for (const [regex, value] of mapping) {
    if (regex.test(lowered)) {
      return value;
    }
  }
  return fallback;
};

const extractColors = (prompt: string) => {
  const lowered = prompt.toLowerCase();
  const entries: Array<[RegExp, string]> = [
    [/(bleu|azur|cobalt)/, "bleue"],
    [/(violet|mauve|pourpre)/, "violette"],
    [/(vert|√©meraude|menthe)/, "verte"],
    [/(rouge|cramoisi|bordeaux)/, "rouge"],
    [/(rose|fuchsia|magenta)/, "rose"],
    [/(orange|ambre|cuivre)/, "orang√©e"],
    [/(dor[√©e]|or|gold)/, "dor√©e"],
    [/(argent|m√©tal|chrome)/, "argent√©e"],
    [/(noir|sombre|charbon)/, "sombre"],
    [/(blanc|clair|ivoire)/, "lumineuse"],
  ];

  const detected = entries
    .filter(([regex]) => regex.test(lowered))
    .map(([, value]) => value);

  if (!detected.length) return "harmonie contrast√©e";
  if (detected.length === 1) return `palette ${detected[0]}`;
  return `palette ${detected[0]} et ${detected[1]}`;
};

const IMAGE_RATIO_CONFIG: Record<
  Exclude<ImageAspectRatio, "custom">,
  { width: number; height: number; label: string }
> = {
  "2:3": { width: 832, height: 1248, label: "portrait" },
  "1:1": { width: 1024, height: 1024, label: "carr√©" },
  "16:9": { width: 1280, height: 720, label: "paysage" },
  "3:2": { width: 1200, height: 800, label: "photo paysage" },
  "4:5": { width: 1024, height: 1280, label: "portrait social" },
  "5:4": { width: 1280, height: 1024, label: "affiche" },
  "21:9": { width: 1792, height: 768, label: "ultra large" },
  "9:16": { width: 832, height: 1472, label: "vertical" },
};

const STYLE_PRESET_LABELS: Record<string, string> = {
  "3d-render": "rendu 3D photor√©aliste",
  acrylic: "texture acrylique vibrante",
  cinematic: "style cin√©matique haut contraste",
  creative: "composition cr√©ative exp√©rimentale",
  dynamic: "style dynamique et √©nergique",
  fashion: "mode √©ditoriale lumineuse",
  "game-concept": "concept art de jeu vid√©o",
  "graphic-2d": "graphisme 2D moderne",
  "graphic-3d": "graphisme 3D premium",
  illustration: "illustration d√©taill√©e",
  portrait: "portrait studio",
  "portrait-cinematic": "portrait cin√©matique dramatique",
  "portrait-fashion": "portrait fashion magazine",
  "pro-bw": "photographie noir et blanc professionnelle",
  "pro-color": "photographie couleur professionnelle",
  "pro-film": "grain pellicule cin√©matographique",
  "ray-traced": "rendu ray tracing hyper r√©aliste",
  "stock-photo": "photo stock commerciale",
};

const STYLE_PRESET_PROMPTS: Record<string, string> = {
  "3d-render": "hyper detailed 3d render with global illumination",
  acrylic: "acrylic painting strokes and vivid pigments",
  cinematic: "cinematic lighting, anamorphic lens, film still",
  creative: "experimental creative composition, surreal details",
  dynamic: "dynamic action lighting, motion design energy",
  fashion: "high fashion editorial photography, studio lighting",
  "game-concept": "AAA game concept art, dramatic lighting",
  "graphic-2d": "premium 2d graphic design, clean vector shapes",
  "graphic-3d": "3d graphic render, chrome reflections",
  illustration: "highly detailed illustration, painterly",
  portrait: "studio portrait photography, crisp focus",
  "portrait-cinematic": "cinematic portrait lighting, shallow depth of field",
  "portrait-fashion": "fashion portrait, editorial styling",
  "pro-bw": "professional black and white photography, rich contrast",
  "pro-color": "professional color grading, vibrant yet natural tones",
  "pro-film": "analog film photography, fine grain, warm tones",
  "ray-traced": "ray traced lighting, physically accurate reflections",
  "stock-photo": "commercial stock photo, high clarity",
};

const DEFAULT_IMAGE_SETTINGS: ImageGenerationSettings = {
  promptEnhance: true,
  aspectRatio: "3:2",
  customDimensions: {
    width: IMAGE_RATIO_CONFIG["3:2"].width,
    height: IMAGE_RATIO_CONFIG["3:2"].height,
  },
  imageCount: 1,
  isPrivate: false,
  stylePreset: undefined,
  advanced: {
    guidanceScale: 12,
    stepCount: 40,
    seed: "",
    upscale: true,
    highResolution: false,
    negativePrompt: "",
  },
};

const resolveAspectRatioDetails = (settings?: ImageGenerationSettings) => {
  const ratio = settings?.aspectRatio ?? "3:2";
  if (ratio === "custom") {
    const dimensions = settings?.customDimensions ?? {
      width: 1536,
      height: 1024,
    };
    return {
      ratio,
      label: "personnalis√©",
      width: dimensions.width,
      height: dimensions.height,
      readable: `${dimensions.width} √ó ${dimensions.height}`,
    };
  }

  const config = IMAGE_RATIO_CONFIG[ratio] ?? IMAGE_RATIO_CONFIG["3:2"];
  return {
    ratio,
    label: config.label,
    width: config.width,
    height: config.height,
    readable: `${config.width} √ó ${config.height}`,
  };
};

const describeStylePreset = (settings?: ImageGenerationSettings) => {
  if (!settings?.stylePreset) {
    return "style libre √©quilibr√©";
  }
  return STYLE_PRESET_LABELS[settings.stylePreset] ?? settings.stylePreset;
};

const buildImageSettingsInstructions = (settings: ImageGenerationSettings) => {
  const ratioDetails = resolveAspectRatioDetails(settings);
  const styleDescription = describeStylePreset(settings);
  const advanced = settings.advanced;
  const instructions: string[] = [
    `Format demand√© : ${ratioDetails.label} ${ratioDetails.readable}.`,
    `Nombre de variations : ${settings.imageCount}.`,
    `Style artistique : ${styleDescription}.`,
  ];

  if (settings.promptEnhance) {
    instructions.push("Utilise un prompt descriptif riche et d√©taill√©.");
  } else {
    instructions.push(
      "Interpr√®te le prompt tel quel, sans extrapolation inutile.",
    );
  }

  if (advanced.upscale) {
    instructions.push(
      "Pr√©voyez une passe d'upscale pour maximiser les d√©tails.",
    );
  }
  if (advanced.highResolution) {
    instructions.push("Optimise pour un rendu haute r√©solution.");
  }

  instructions.push(
    `Param√®tres souhait√©s : guidance ${advanced.guidanceScale} ¬∑ steps ${advanced.stepCount}.`,
  );

  if (advanced.seed.trim()) {
    instructions.push(`Conserve le seed ${advanced.seed.trim()} si possible.`);
  }

  if (advanced.negativePrompt.trim()) {
    instructions.push(`√âvite absolument : ${advanced.negativePrompt.trim()}.`);
  }

  return [
    "Contraintes techniques :",
    ...instructions.map((line) => `- ${line}`),
  ].join("\n");
};

const createImagePlan = (
  prompt: string,
  modification?: string,
  settings?: ImageGenerationSettings,
): GenerationPlan => {
  const subject = detectKeyword(
    prompt,
    [
      [/(produit|packshot|marchand)/, "mise en sc√®ne produit"],
      [/(portrait|visage|personnage|personne)/, "portrait expressif"],
      [/(paysage|nature|montagne|mer|for√™t)/, "paysage immersif"],
      [/(architecture|ville|urbain)/, "architecture stylis√©e"],
    ],
    "composition conceptuelle",
  );
  const mood = detectKeyword(
    prompt,
    [
      [/(sombre|dramatique|noir)/, "ambiance sombre cin√©matique"],
      [/(lumineux|clair|a√©rien|soleil)/, "ambiance lumineuse et positive"],
      [/(futuriste|n√©on|cyber|synthwave)/, "ambiance futuriste aux n√©ons"],
      [/(myst√©rieux|onirique|fantastique)/, "ambiance onirique et myst√©rieuse"],
    ],
    "ambiance √©quilibr√©e",
  );
  const style = detectKeyword(
    prompt,
    [
      [/(aquarelle|gouache)/, "style aquarelle"],
      [/(huile|peinture)/, "style peinture digitale"],
      [/(vectoriel|flat|minimal)/, "style vectoriel minimaliste"],
      [/(3d|isom√©trique|low poly)/, "style 3D isom√©trique"],
      [/(photo|photographique|r√©aliste)/, "style photo-r√©aliste"],
    ],
    "style illustratif moderne",
  );
  const perspective = detectKeyword(
    prompt,
    [
      [/(plong√©e|vue du dessus)/, "vue en plong√©e"],
      [/(contre[- ]plong√©e|imposant)/, "contre-plong√©e dramatique"],
      [/(panoramique|large|cin√©mascope)/, "cadre large panoramique"],
    ],
    "cadre frontal √©quilibr√©",
  );
  const palette = extractColors(prompt);
  const ratioDetails = resolveAspectRatioDetails(settings);
  const styleDescription = describeStylePreset(settings);
  const imageCount = settings?.imageCount ?? 1;
  const promptEnhance = settings?.promptEnhance ? "activ√©e" : "d√©sactiv√©e";

  const sections: PlanSection[] = [
    {
      title: "Analyse du brief",
      objective:
        "Clarifier sujet, ambiance et contraintes avant de produire l'image.",
      steps: [
        {
          id: "subject",
          title: "Identifier le sujet cl√©",
          description: `Mettre l'accent sur ${subject} avec ${perspective}.`,
          deliverable: "Sujet cadr√©",
        },
        {
          id: "style",
          title: "Valider le style",
          description: `Confirmer un ${style} coh√©rent dans ${mood}.`,
          deliverable: "R√©f√©rences visuelles",
        },
        {
          id: "palette",
          title: "Lister la palette",
          description: `D√©ployer une ${palette} adapt√©e au brief.`,
          deliverable: "Palette finale",
        },
      ],
    },
    {
      title: "Orchestration Leonardo Phoenix",
      objective:
        "Pr√©parer les invites et param√®tres pour Leonardo Phoenix et garantir un rendu contr√¥l√© et coh√©rent.",
      steps: [
        {
          id: "prompting",
          title: "R√©diger l'invite ma√Ætre",
          description:
            "Structurer un prompt hi√©rarchis√© (sujet ¬∑ ambiance ¬∑ composition ¬∑ d√©tails) accompagn√© d'un prompt n√©gatif robuste.",
          deliverable: "Prompt Phoenix optimis√©",
        },
        {
          id: "passes",
          title: "Configurer les passes",
          description:
            "D√©finir passes base, d√©tail et coh√©rence lumi√®re (CFG, steps, seed partag√©) et pr√©voir une passe upscale.",
          deliverable: "Plan de passes calibr√©",
        },
        {
          id: "quality",
          title: "S√©curiser la qualit√©",
          description:
            "Lister crit√®res de rehausse : nettet√©, contr√¥le du bruit, coh√©rence anatomique, export HD/4K.",
          deliverable: "Checklist qualit√© Leonardo",
        },
      ],
    },
    {
      title: "Composition et d√©tails",
      objective: "Structurer la sc√®ne puis affiner lumi√®re et textures.",
      steps: [
        {
          id: "composition",
          title: "Esquisser la composition",
          description: `D√©finir masses principales et profondeur selon ${perspective}.`,
          deliverable: "Croquis composition",
        },
        {
          id: "lighting",
          title: "Placer la lumi√®re",
          description: `Installer une lumi√®re ${mood.replace("ambiance ", "")}.`,
          deliverable: "Sch√©ma lumineux",
        },
        {
          id: "details",
          title: "Ajouter les d√©tails",
          description:
            "Int√©grer textures, accessoires et d√©cor pour soutenir le r√©cit visuel.",
          deliverable: "D√©tails finalis√©s",
        },
      ],
    },
    {
      title: "Finitions",
      objective: "V√©rifier coh√©rence et pr√©parer l'export final.",
      steps: [
        {
          id: "grading",
          title: "Uniformiser les couleurs",
          description:
            "Appliquer un color grading l√©ger pour harmoniser l'image.",
          deliverable: "Palette harmonis√©e",
        },
        {
          id: "export",
          title: "Pr√©parer le rendu",
          description:
            "Exporter en haute d√©finition, format adapt√© au support (PNG/WEBP).",
          deliverable: "Fichier final",
        },
      ],
    },
  ];

  const summarySuffix = modification ? ` (ajustement : ${modification})` : "";

  return {
    title: "Plan de g√©n√©ration d'image",
    summary: `Cr√©er une illustration ${style} centr√©e sur ${subject} dans ${mood} (${ratioDetails.label} ${ratioDetails.readable}, ${imageCount} variante(s), am√©lioration ${promptEnhance}) avec Leonardo Phoenix${summarySuffix}`,
    sections,
    successCriteria: [
      "Sujet et ambiance fid√®les au brief",
      "Composition lisible avec profondeur",
      "Palette harmonieuse et coh√©rente",
      "Param√®tres Leonardo document√©s pour reproductibilit√©",
      `Style cibl√© : ${styleDescription}`,
    ],
    cautions: [
      "Respecter la perspective et les proportions des √©l√©ments",
      "Adapter le niveau de d√©tail selon le support d'utilisation",
      "Contr√¥ler l'usage des assets tiers pour √©viter les artefacts IA",
    ],
  };
};

const generateImageResult = (options: GenerationOptions): GeneratedResult => {
  const { prompt, version, modification, imageSettings } = options;
  const effectiveSettings = imageSettings ?? DEFAULT_IMAGE_SETTINGS;
  const ratioDetails = resolveAspectRatioDetails(effectiveSettings);
  const styleDescriptor = describeStylePreset(effectiveSettings);
  const providedSeed = effectiveSettings.advanced.seed.trim();
  const hashInput = [
    prompt,
    modification ?? "",
    ratioDetails.readable,
    effectiveSettings.stylePreset ?? "libre",
    effectiveSettings.promptEnhance ? "enhance" : "raw",
    providedSeed,
  ].join("|");
  const hash = simpleHash(hashInput);

  const palettes = [
    "d√©grad√© cobalt ¬∑ indigo ¬∑ lueur lavande",
    "sable chaud ¬∑ orange sanguine ¬∑ violet √©lectrique",
    "menthe givr√©e ¬∑ turquoise n√©on ¬∑ argent chrom√©",
    "graphite profond ¬∑ cuivre fum√© ¬∑ bleu polaire",
    "ivoire nacr√© ¬∑ dor√© champagne ¬∑ rose quartz",
  ];
  const renderStyles = [
    "cin√©matique ultra-r√©aliste",
    "peinture digitale textur√©e",
    "illustration vectorielle premium",
    "3D hybride photor√©aliste",
    "aquarelle pigment√©e haut contraste",
  ];
  const cameraAngles = [
    "optique 35mm √† hauteur d'≈ìil",
    "optique tilt-shift panoramique",
    "plong√©e architecturale dramatique",
    "contre-plong√©e √©pique",
    "plan large cin√©mascope",
  ];
  const lighting = [
    "√©clairage volum√©trique √† double rim light",
    "setup studio trois points + rebond dor√©",
    "lumi√®re naturelle diffuse avec rayons godrays",
    "ambiance nocturne n√©on et reflets humides",
    "clair-obscur ma√Ætris√© avec fill doux",
  ];
  const focus = [
    "profondeur de champ f/1.8",
    "focus stacking macro",
    "mise au point douce sur le sujet principal",
    "nettet√© uniforme f/8",
    "bokeh cin√©tique",
  ];

  const finalSeed =
    providedSeed && providedSeed.length > 0
      ? providedSeed
      : (hash % 10_000_000).toString().padStart(7, "0");
  const steps = effectiveSettings.advanced.stepCount ?? 40 + (hash % 10);
  const cfgValue = effectiveSettings.advanced.guidanceScale ?? 11 + (hash % 4);
  const sampler = pick(
    ["LEO-FineDetail", "LEO-Contrast", "LEO-DreamWeaver"],
    hash,
    9,
  );
  const palette = pick(palettes, hash, 1);
  const fallbackStyle = pick(renderStyles, hash, 3);
  const angle = pick(cameraAngles, hash, 5);
  const lights = pick(lighting, hash, 7);
  const focusStyle = pick(focus, hash, 11);
  const stylePrompt = effectiveSettings.stylePreset
    ? (STYLE_PRESET_PROMPTS[effectiveSettings.stylePreset] ?? styleDescriptor)
    : fallbackStyle;

  const masterPrompt = [
    effectiveSettings.promptEnhance
      ? `highly descriptive prompt: ${prompt.trim()}`
      : prompt.trim(),
    stylePrompt,
    angle,
    lights,
    focusStyle,
    `palette ${palette}`,
    effectiveSettings.advanced.highResolution
      ? "leonardo high fidelity rendering"
      : "",
    effectiveSettings.advanced.upscale ? "detail-preserving upscaler" : "",
  ]
    .filter(Boolean)
    .join(" ¬∑ ");

  const negativePromptParts = [
    "artefacts num√©riques",
    "distorsion anatomique",
    "texte",
    "filigrane",
    "sur-exposition",
  ];
  if (effectiveSettings.advanced.negativePrompt.trim()) {
    negativePromptParts.push(effectiveSettings.advanced.negativePrompt.trim());
  }
  const negativePrompt = negativePromptParts.join(", ");

  const preview = `https://picsum.photos/seed/leonardo-${encodeURIComponent(`${hash}-${version}`)}/${ratioDetails.width}/${ratioDetails.height}`;

  const settingsSummary = [
    `- Prompt enhance : ${effectiveSettings.promptEnhance ? "activ√©" : "d√©sactiv√©"}`,
    `- Format : ${ratioDetails.readable} (${ratioDetails.label})`,
    `- Variations : ${effectiveSettings.imageCount}`,
    `- Style : ${styleDescriptor}`,
    `- Confidentialit√© : ${effectiveSettings.isPrivate ? "priv√©e" : "publique"}`,
    `- Upscale : ${effectiveSettings.advanced.upscale ? "oui" : "non"} ¬∑ Haute r√©solution : ${effectiveSettings.advanced.highResolution ? "oui" : "non"}`,
    `- Guidance : ${cfgValue} ¬∑ Steps : ${steps}`,
    `- Seed : ${finalSeed || "al√©atoire"}`,
  ];
  if (effectiveSettings.advanced.negativePrompt.trim()) {
    settingsSummary.push(
      `- Prompt n√©gatif personnalis√© : ${effectiveSettings.advanced.negativePrompt.trim()}`,
    );
  }

  const content = [
    "üß† Analyse Phoenix",
    `- Intention principale : ${prompt.trim() || "visuel conceptuel"}.`,
    `- Variation demand√©e : ${modification ?? "premi√®re exploration"}.`,
    `- Style retenu : ${stylePrompt} ¬∑ ${palette}.`,
    "",
    "üé® Prompt Leonardo Phoenix 1.1",
    "```",
    masterPrompt,
    "```",
    "",
    "üö´ Prompt n√©gatif",
    "```",
    negativePrompt,
    "```",
    "",
    "üéõÔ∏è Param√©trage recommand√©",
    `- Mod√®le : Leonardo Phoenix 1.1 ¬∑ Sampler : ${sampler}`,
    `- Steps : ${steps} ¬∑ Guidance : ${cfgValue}`,
    `- Seed : ${finalSeed || "al√©atoire"} ¬∑ Ratio : ${ratioDetails.readable}`,
    `- Upscale : ${effectiveSettings.advanced.upscale ? "activ√©" : "d√©sactiv√©"} ¬∑ Mode HD : ${effectiveSettings.advanced.highResolution ? "activ√©" : "d√©sactiv√©"}`,
    "",
    "üìã Param√®tres Leonardo",
    ...settingsSummary,
    "",
    "üìù Checklist qualit√©",
    "- V√©rifier coh√©rence lumi√®re / profondeur",
    "- Inspecter d√©tails critiques (mains, typographie, textures)",
    "- Exporter une version HD + variante Web optimis√©e",
  ].join("\n");

  return {
    type: "image",
    category: TOOL_LABELS.image,
    prompt,
    version,
    modification,
    preview,
    content,
    imageSettings: effectiveSettings,
  };
};

const generateMusicResult = (options: GenerationOptions): GeneratedResult => {
  const { prompt, version, modification } = options;
  const hash = simpleHash([prompt, modification ?? ""].join("|"));

  const moods = [
    "chillwave nocturne",
    "cin√©matique h√©ro√Øque",
    "house organique",
    "synthwave r√©tro",
    "ambient m√©ditatif",
  ];
  const structures = [
    "intro a√©rienne ‚Üí mont√©e textur√©e ‚Üí drop principal ‚Üí pont respirant ‚Üí final √©volutif",
    "pr√©lude intimiste ‚Üí premier th√®me ‚Üí d√©veloppement rythmique ‚Üí climax orchestral ‚Üí coda douce",
    "hook imm√©diat ‚Üí couplet percussif ‚Üí refrain expansif ‚Üí break minimal ‚Üí reprise √©nergique",
  ];
  const instrumentStacks = [
    "pads analogiques, basse ronde sidechain√©e, arp√®ges cristallins",
    "section cordes hybride, cuivres cin√©matiques, impacts percussifs",
    "guitare √©lectrique delay, batterie acoustique trait√©e, textures granulaires",
    "piano feutr√©, drones modulaires, percussions organiques",
    "lead FM r√©tro, drums √©lectroniques punchy, choeurs textur√©s",
  ];
  const rhythmIdeas = [
    "groove breakbeat syncop√©",
    "pattern 4/4 club progressif",
    "pulse trip-hop downtempo",
    "balancement halftime futuriste",
    "cadence pop uptempo",
  ];
  const mixingNotes = [
    "Sculpte un espace st√©r√©o large avec reverbs plates et delays ping-pong.",
    "Automatise filtres passe-haut pour les transitions et sidechain subtil sur les pads.",
    "Ajoute une saturation bande l√©g√®re sur le bus master pour coller l'ensemble.",
    "Pr√©vois une automation de largeur st√©r√©o crescendo vers le drop.",
  ];

  const bpm = [84, 96, 104, 118, 122][hash % 5];
  const scale = [
    "La mineur",
    "R√© majeur",
    "Do# mineur",
    "Sol mineur",
    "Mi majeur",
  ][hash % 5];

  const content = [
    `üéº Concept : ${pick(moods, hash, 0)} ¬∑ ${bpm} BPM ¬∑ tonalit√© ${scale}.`,
    `üéöÔ∏è Structure : ${pick(structures, hash, 3)}.`,
    "",
    "üß© Arrangement conseill√©",
    `- Stack instrumental : ${pick(instrumentStacks, hash, 5)}.`,
    `- Rythme principal : ${pick(rhythmIdeas, hash, 7)}.`,
    "- Variations : couche un motif secondaire toutes les 16 mesures pour relancer l'√©nergie.",
    "- Texture : captures de terrain et foley l√©gers pour renforcer le storytelling.",
    "",
    "üéõÔ∏è Direction de production",
    `- Sound design : cr√©e 3 versions du lead pour ${modification ? "int√©grer l'ajustement" : "proposer une palette"} contrast√©e (clean ¬∑ satur√©e ¬∑ granuleuse).`,
    "- Harmonise les transitions avec risers invers√©s et impacts trait√©s par convolution.",
    `- ${pick(mixingNotes, hash, 11)}`,
    "",
    "üìù Livrables",
    "- Stems s√©par√©s (drums / basse / harmo / FX / voix).",
    "- Export master -14 LUFS, headroom 1 dB, format WAV 24 bits.",
    "- Version courte 30 s pour social media.",
  ].join("\n");

  return {
    type: "text",
    category: TOOL_LABELS.music,
    prompt,
    version,
    modification,
    content,
  };
};

const generateAgentResult = (options: GenerationOptions): GeneratedResult => {
  const { prompt, version, modification } = options;
  const hash = simpleHash([prompt, modification ?? ""].join("|"));

  const nameBase = prompt
    .toLowerCase()
    .replace(/[^a-z0-9]+/g, "-")
    .replace(/^-+|-+$/g, "")
    .slice(0, 32)
    .replace(/-+/g, "-");
  const projectSlug = nameBase || `python-agent-${hash % 10_000}`;
  const projectName = projectSlug
    .split("-")
    .map((part) => part.charAt(0).toUpperCase() + part.slice(1))
    .join(" ");

  const objectives = [
    "analyse strat√©gique hebdomadaire",
    "synth√®se automatis√©e des insights clients",
    "g√©n√©ration d'id√©es de contenu cibl√©es",
    "priorisation de backlog produit",
    "veille concurrentielle structur√©e",
  ];
  const toolkit = [
    "Notion API",
    "Slack webhooks",
    "Google Sheets",
    "Linear API",
    "HubSpot",
  ];

  const focusObjective = pick(objectives, hash, 1);
  const integration = pick(toolkit, hash, 4);
  const packageName = projectSlug.replace(/-/g, "_");

  const instructions = [
    "## Installation",
    "```bash",
    "python -m venv .venv",
    "source .venv/bin/activate # ou .venv\\Scripts\\activate sous Windows",
    "pip install -e .",
    "cp .env.example .env",
    "```",
    "",
    "## Configuration",
    "1. Renseignez votre cl√© OpenAI et les identifiants API n√©cessaires dans `.env`.",
    `2. Ajustez \`AGENT_OBJECTIVE\` et \`PRIMARY_INTEGRATION\` dans \`src/${packageName}/config.py\`.`,
    "3. Lancez les tests rapides :",
    "```bash",
    "pytest",
    "```",
    "",
    "## Ex√©cution",
    "```bash",
    `python -m ${packageName}.cli task "D√©crivez la prochaine action"`,
    "```",
    "",
    "Le module FastAPI optionnel peut √™tre lanc√© via :",
    "```bash",
    "uvicorn server.app:app --reload",
    "```",
  ].join("\n");

  const files: GeneratedResult["files"] = [
    {
      path: "pyproject.toml",
      language: "toml",
      content: [
        "[build-system]",
        'requires = ["setuptools>=65", "wheel"]',
        'build-backend = "setuptools.build_meta"',
        "",
        "[project]",
        `name = "${projectSlug}"`,
        'version = "0.1.0"',
        `description = "Agent Python pour ${focusObjective}"`,
        'authors = [{ name = "Studio One" }]',
        'requires-python = ">=3.10"',
        "dependencies = [",
        '  "openai>=1.13",',
        '  "python-dotenv>=1.0",',
        '  "typer>=0.9",',
        '  "httpx>=0.26",',
        '  "rich>=13.7",',
        '  "fastapi>=0.110",',
        '  "uvicorn[standard]>=0.27",',
        '  "pydantic>=2.6",',
        "]",
        "",
        "[project.scripts]",
        `${projectSlug} = "${packageName}.cli:app"`,
      ].join("\n"),
    },
    {
      path: "README.md",
      language: "markdown",
      content: [
        `# ${projectName}`,
        "",
        `Agent autonome focalis√© sur ${focusObjective}. Il orchestre des appels OpenAI et ${integration} √† partir d'un pipeline orchestr√© par Typer + FastAPI.`,
        "",
        "## Flux de travail",
        `1. Collecte les inputs utilisateur et contexte depuis ${integration}.`,
        "2. Raisonne avec une boucle planifier ‚Üí ex√©cuter ‚Üí r√©viser via l'API OpenAI.",
        "3. Produit un rapport structur√© et d√©clenche, si n√©cessaire, un message sortant.",
        "",
        "## D√©marrage rapide",
        "",
        instructions,
      ].join("\n"),
    },
    {
      path: ".env.example",
      content: [
        "OPENAI_API_KEY=sk-...",
        "PRIMARY_INTEGRATION_TOKEN=replace-me",
        "LOG_LEVEL=INFO",
      ].join("\n"),
    },
    {
      path: `src/${packageName}/__init__.py`,
      language: "python",
      content: ['"""Metadata for package."""', '__all__ = ["run_agent"]'].join(
        "\n",
      ),
    },
    {
      path: `src/${packageName}/config.py`,
      language: "python",
      content: [
        "from pydantic import BaseSettings, Field",
        "",
        "",
        "class Settings(BaseSettings):",
        '    """Application configuration loaded from environment."""',
        "",
        '    openai_api_key: str = Field(alias="OPENAI_API_KEY")',
        '    primary_integration_token: str = Field(alias="PRIMARY_INTEGRATION_TOKEN")',
        '    log_level: str = Field(default="INFO")',
        `    agent_objective: str = Field(default="${focusObjective}")`,
        `    primary_integration: str = Field(default="${integration}")`,
        "",
        '    model_config = {"env_file": ".env", "extra": "ignore"}',
        "",
        "",
        "settings = Settings()",
      ].join("\n"),
    },
    {
      path: `src/${packageName}/agent.py`,
      language: "python",
      content: [
        '"""Core reasoning loop for the autonomous agent."""',
        "from __future__ import annotations",
        "",
        "from typing import List",
        "",
        "import httpx",
        "from openai import OpenAI",
        "from rich.console import Console",
        "",
        "from .config import settings",
        "from .integrations import IntegrationClient",
        "",
        "console = Console()",
        "client = OpenAI(api_key=settings.openai_api_key)",
        "",
        `SYSTEM_PROMPT = f"Vous √™tes un agent sp√©cialis√© dans ${focusObjective}."`,
        "",
        "",
        "def plan_tasks(goal: str) -> List[str]:",
        "    response = client.responses.create(",
        '        model="gpt-4.1-mini",',
        "        input=[",
        '            {"role": "system", "content": SYSTEM_PROMPT},',
        '            {"role": "user", "content": f"Planifie 3 √©tapes pour : {goal}"},',
        "        ],",
        "    )",
        '    steps = response.output_text.split("\n")',
        '    return [step.strip("- ‚Ä¢") for step in steps if step.strip()]',
        "",
        "",
        "def run_agent(goal: str) -> str:",
        '    console.rule("D√©marrage de l\'agent")',
        "    steps = plan_tasks(goal)",
        "    integration = IntegrationClient(settings)",
        "",
        "    results: List[str] = []",
        "    for index, step in enumerate(steps, start=1):",
        '        console.print(f"[bold cyan]√âtape {index}[/]: {step}")',
        "        context = integration.fetch_context(step)",
        "        response = client.responses.create(",
        '            model="gpt-4.1-mini",',
        "            input=[",
        '                {"role": "system", "content": SYSTEM_PROMPT},',
        '                {"role": "user", "content": f"Objectif: {goal}\\n√âtape: {step}\\nContexte: {context}"},',
        "            ],",
        "        )",
        "        summary = response.output_text.strip()",
        "        integration.push_update(step, summary)",
        '        results.append(f"√âtape {index}: {summary}")',
        "",
        '    console.rule("Synth√®se")',
        '    return "\n".join(results)',
      ].join("\n"),
    },
    {
      path: `src/${packageName}/integrations.py`,
      language: "python",
      content: [
        `"""Integration shim for ${integration}."""`,
        "from __future__ import annotations",
        "",
        "from .config import Settings",
        "",
        "",
        "class IntegrationClient:",
        '    """Very small abstraction over external integrations."""',
        "",
        "    def __init__(self, settings: Settings) -> None:",
        "        self._settings = settings",
        "",
        "    def fetch_context(self, query: str) -> str:",
        '        """Retrieve context related to the current task."""',
        `        return f"Contexte simul√© pour '{query}' via {self._settings.primary_integration}."`,
        "",
        "    def push_update(self, step: str, summary: str) -> None:",
        '        """Send the agent decision to the integration."""',
        "        _ = step, summary  # Ici on branchera l'appel API r√©el.",
      ].join("\n"),
    },
    {
      path: `src/${packageName}/cli.py`,
      language: "python",
      content: [
        '"""Command line interface to interact with the agent."""',
        "from __future__ import annotations",
        "",
        "import typer",
        "",
        "from .agent import run_agent",
        "",
        'app = typer.Typer(help="Assistant intelligent orchestr√© par OpenAI")',
        "",
        "@app.command()",
        'def task(description: str = typer.Argument(..., help="Objectif √† analyser")) -> None:',
        '    """Ex√©cute le flux principal de l\'agent."""',
        "    result = run_agent(description)",
        '    typer.echo("\n" + result)',
        "",
        'if __name__ == "__main__":',
        "    app()",
      ].join("\n"),
    },
    {
      path: "server/app.py",
      language: "python",
      content: [
        '"""Minimal FastAPI wrapper exposing the agent."""',
        "from __future__ import annotations",
        "",
        "from fastapi import FastAPI",
        "",
        `from ${packageName}.agent import run_agent`,
        "",
        `app = FastAPI(title="${projectName}")`,
        "",
        '@app.post("/run")',
        "async def run(payload: dict[str, str]) -> dict[str, str]:",
        '    goal = payload.get("goal", "Analyse g√©n√©rale")',
        "    report = run_agent(goal)",
        '    return {"goal": goal, "report": report}',
      ].join("\n"),
    },
    {
      path: "tests/test_agent.py",
      language: "python",
      content: [
        '"""Smoke tests for agent entrypoints."""',
        "from __future__ import annotations",
        "",
        `from ${packageName}.agent import plan_tasks`,
        "",
        "",
        "def test_plan_tasks_generates_steps():",
        '    steps = plan_tasks("Analyser un lancement produit")',
        '    assert steps, "Planification vide"',
      ].join("\n"),
    },
  ];

  const content = [
    `üß† Objectif : ${focusObjective}.`,
    `üîå Int√©gration principale : ${integration}.`,
    "‚öôÔ∏è Stack : OpenAI Responses API ¬∑ Typer CLI ¬∑ FastAPI service ¬∑ Pydantic Settings.",
    `üìÅ Projet : ${projectName} (${projectSlug}).`,
  ].join("\n");

  return {
    type: "code",
    category: TOOL_LABELS.agent,
    prompt,
    version,
    modification,
    projectName,
    projectType: "python-agent",
    content,
    instructions,
    files,
  };
};

const createMusicPlan = (
  prompt: string,
  modification?: string,
): GenerationPlan => {
  const atmosphere = detectKeyword(
    prompt,
    [
      [/(calme|relax|ambient|lo[- ]?fi)/, "ambiance chill immersive"],
      [/(√©nergique|dance|club|punchy)/, "ambiance √©nergique et entra√Ænante"],
      [/(cin√©matique|√©pique|orchestrale)/, "ambiance cin√©matique grandiose"],
      [/(nostalgique|r√©tro|vintage)/, "ambiance r√©tro nostalgique"],
    ],
    "ambiance contemporaine √©quilibr√©e",
  );
  const tempo = detectKeyword(
    prompt,
    [
      [/(lent|slow|downtempo)/, "72-88 BPM"],
      [/(mod√©r√©|mid|groove)/, "92-108 BPM"],
      [/(rapide|upbeat|dance)/, "118-128 BPM"],
    ],
    "100 BPM",
  );
  const instrumentation = detectKeyword(
    prompt,
    [
      [
        /(percussions|tribal|organic)/,
        "percussions organiques et textures granulaires",
      ],
      [/(synth|electro|analog)/, "synth√©s analogiques puls√©s"],
      [/(acoustique|guitare|piano)/, "instrumentation acoustique intimiste"],
    ],
    "basse ronde et pads atmosph√©riques",
  );

  const sections: PlanSection[] = [
    {
      title: "Analyse musicale",
      objective:
        "Comprendre l'univers sonore souhait√© et cadrer les contraintes techniques.",
      steps: [
        {
          id: "ambiance",
          title: "Qualifier l'ambiance",
          description: `Traduire ${atmosphere} avec un tempo ${tempo}.`,
          deliverable: "Moodboard sonore",
        },
        {
          id: "structure",
          title: "Tracer la structure",
          description:
            "D√©couper le morceau en intro, sections A/B, pont et outro.",
          deliverable: "Plan de structure",
        },
      ],
    },
    {
      title: "Pilotage Gemini 2.5",
      objective:
        "Exploiter Gemini 2.5 pour proposer des variations harmoniques et un storytelling sonore raffin√©.",
      steps: [
        {
          id: "ideation",
          title: "It√©rer sur les id√©es",
          description:
            "G√©n√©rer trois sc√©narios √©motionnels avec Gemini 2.5 (intro, mont√©e, climax) et s√©lectionner le meilleur.",
          deliverable: "Storyboard sonore valid√©",
        },
        {
          id: "arrangement-ai",
          title: "Affiner les arrangements",
          description:
            "Demander √† Gemini 2.5 des suggestions de layering (pads, arp√®ges, textures) selon l'ambiance.",
          deliverable: "Pistes d'arrangement IA",
        },
        {
          id: "lyrics",
          title: "Option paroles",
          description:
            "Si n√©cessaire, g√©n√©rer un texte court ou des noms de piste coh√©rents avec l'√©motion cibl√©e.",
          deliverable: "Paroles / titres g√©n√©r√©s",
        },
      ],
    },
    {
      title: "Composition",
      objective:
        "Construire harmonie, motifs et transitions pour soutenir le r√©cit musical.",
      steps: [
        {
          id: "harmonie",
          title: "Choisir l'harmonie",
          description: "D√©terminer tonalit√© et progression principale.",
          deliverable: "Grille d'accords",
        },
        {
          id: "motifs",
          title: "√âcrire les motifs",
          description: `Cr√©er un hook m√©morable et un motif de basse ${instrumentation}.`,
          deliverable: "Motifs principaux",
        },
        {
          id: "transitions",
          title: "Pr√©parer les transitions",
          description:
            "Utiliser mont√©es, impacts et textures pour relier les sections.",
          deliverable: "Automation des transitions",
        },
      ],
    },
    {
      title: "Production & mix",
      objective: "Arranger, mixer puis pr√©parer l'export final.",
      steps: [
        {
          id: "sound-design",
          title: "S√©lectionner le sound design",
          description:
            "Composer un rack d'instruments coh√©rent (pads, percussions, lead).",
          deliverable: "Palette sonore",
        },
        {
          id: "mix",
          title: "Mixer les stems",
          description:
            "√âquilibrer dynamiques, panoramiques et effets temporels.",
          deliverable: "Mix st√©r√©o √©quilibr√©",
        },
        {
          id: "master",
          title: "Pr√©parer le master",
          description:
            "Appliquer compression glue, EQ douce et limiteur -14 LUFS.",
          deliverable: "Master pr√™t √† diffuser",
        },
      ],
    },
  ];

  const summarySuffix = modification ? ` (modification : ${modification})` : "";

  return {
    title: "Plan de composition musicale",
    summary: `Composer une pi√®ce √† ${tempo} inspir√©e par ${atmosphere} avec l'appui de Gemini 2.5${summarySuffix}`,
    sections,
    successCriteria: [
      "Structure narrative coh√©rente",
      "Motif m√©morable align√© sur l'ambiance",
      "Mix √©quilibr√© pr√™t pour diffusion",
      "Variations Gemini 2.5 document√©es",
    ],
    cautions: [
      "Adapter la dur√©e au format de diffusion vis√©",
      "V√©rifier les droits si des r√©f√©rences sont explicitement cit√©es",
      "Toujours valider artistiquement les propositions IA avant diffusion",
    ],
  };
};

const createAgentPlan = (
  prompt: string,
  modification?: string,
): GenerationPlan => {
  const role = detectKeyword(
    prompt,
    [
      [/(marketing|growth|acquisition)/, "planificateur marketing"],
      [/(produit|product|roadmap)/, "assistant produit strat√©gique"],
      [/(support|client|service)/, "agent support client proactif"],
      [/(data|analyse|analyst)/, "analyste de donn√©es d√©cisionnel"],
    ],
    "assistant polyvalent",
  );
  const tone = detectKeyword(
    prompt,
    [
      [/(amical|chaleureux|humain)/, "ton empathique"],
      [/(formel|professionnel)/, "ton professionnel cadr√©"],
      [/(direct|percutant)/, "ton direct orient√© action"],
    ],
    "ton consultatif",
  );
  const tooling = detectKeyword(
    prompt,
    [
      [/(notion|documentation)/, "Notion pour la base de connaissance"],
      [/(figma|design)/, "Figma pour la collaboration visuelle"],
      [/(slack|communication)/, "Slack pour l'orchestration des √©changes"],
      [/(linear|jira|projet)/, "Linear pour le pilotage des t√¢ches"],
    ],
    "Stack modulaire (Notion + Slack + Google Suite)",
  );

  const sections: PlanSection[] = [
    {
      title: "Cadrage du r√¥le",
      objective: "Transformer le brief en missions concr√®tes pour l'agent.",
      steps: [
        {
          id: "mission",
          title: "Formuler la mission",
          description: `Positionner ${role} et d√©finir ses objectifs prioritaires.`,
          deliverable: "Charte de mission",
        },
        {
          id: "ton",
          title: "Aligner le ton",
          description: `Param√©trer un ${tone} adapt√© √† la cible.`,
          deliverable: "Guide de tonalit√©",
        },
      ],
    },
    {
      title: "Intelligence Gemini 2.5",
      objective:
        "Configurer une boucle de r√©flexion avanc√©e propuls√©e par Gemini 2.5.",
      steps: [
        {
          id: "reasoning",
          title: "D√©finir la r√©flexion",
          description:
            "Sc√©nariser la s√©quence Pense ‚Üí V√©rifie ‚Üí R√©pond pour s√©curiser des r√©ponses argument√©es.",
          deliverable: "Cadre de raisonnement",
        },
        {
          id: "knowledge",
          title: "Indexer les connaissances",
          description:
            "Lister les bases (FAQ, guidelines, historiques) et pr√©voir une mise √† jour automatis√©e.",
          deliverable: "Sources Gemini 2.5",
        },
        {
          id: "handoff-ai",
          title: "Pr√©parer l'escalade",
          description:
            "Configurer les crit√®res de handoff humain avec r√©sum√© g√©n√©r√© par Gemini 2.5.",
          deliverable: "Process d'escalade",
        },
      ],
    },
    {
      title: "Boucle op√©rationnelle",
      objective: "D√©finir les routines et outils utilis√©s par l'agent.",
      steps: [
        {
          id: "inputs",
          title: "Cartographier les entr√©es",
          description:
            "Lister les canaux d'information et signaux d√©clencheurs.",
          deliverable: "Sources et signaux",
        },
        {
          id: "workflow",
          title: "Structurer le workflow",
          description:
            "D√©tailler la s√©quence Observer ‚Üí Analyser ‚Üí Agir ‚Üí Reporter.",
          deliverable: "Workflow d√©taill√©",
        },
        {
          id: "outils",
          title: "Choisir les outils",
          description: `S√©lectionner ${tooling} et d√©finir les permissions.`,
          deliverable: "Stack outils configur√©e",
        },
      ],
    },
    {
      title: "Suivi & am√©lioration",
      objective: "Pr√©voir les m√©triques et le handoff humain.",
      steps: [
        {
          id: "kpi",
          title: "D√©finir les KPIs",
          description: "Identifier 3 indicateurs pour mesurer l'impact.",
          deliverable: "Tableau de bord KPI",
        },
        {
          id: "handoff",
          title: "Planifier le handoff",
          description:
            "Organiser la reprise humaine pour les demandes complexes.",
          deliverable: "Process de reprise",
        },
      ],
    },
  ];

  const summarySuffix = modification ? ` (ajustement : ${modification})` : "";

  return {
    title: "Plan de conception d'agent",
    summary: `Structurer ${role} avec ${tone}, orchestr√© par Gemini 2.5${summarySuffix}`,
    sections,
    successCriteria: [
      "Objectifs mesurables d√©finis",
      "Workflow clair avec outils associ√©s",
      "Routine de reporting pour am√©lioration continue",
      "Prompts et garde-fous Gemini 2.5 document√©s",
    ],
    cautions: [
      "Pr√©voir une supervision humaine avant mise en production",
      "Documenter les limites de l'agent pour cadrer les attentes",
      "Auditer r√©guli√®rement les r√©ponses g√©n√©r√©es par Gemini 2.5",
    ],
  };
};

export const requestCreativeResult = async (
  tool: CreativeTool,
  options: GenerationOptions,
): Promise<GeneratedResult> => {
  if (
    !import.meta.env.VITE_SUPABASE_URL ||
    !import.meta.env.VITE_SUPABASE_PUBLISHABLE_KEY
  ) {
    throw new Error("Configuration Supabase manquante");
  }

  const { prompt, version, modification, previous, imageSettings, plan } =
    options;
  const shouldAppendImageSettings = tool === "image" && imageSettings;
  const enrichedPrompt = shouldAppendImageSettings
    ? [prompt.trim(), buildImageSettingsInstructions(imageSettings!)]
        .filter(Boolean)
        .join("\n\n")
    : prompt;

  const { data, error } = await supabase.functions.invoke("generate-content", {
    body: {
      prompt: enrichedPrompt,
      category: tool,
      modification: modification?.trim() ? modification : undefined,
      existingContent: previous?.content?.trim() ? previous.content : undefined,
      plan: plan ?? undefined,
      mode: "content",
      imageSettings: tool === "image" ? imageSettings : undefined,
    },
  });

  if (error) {
    throw new Error(error.message);
  }

  const payload = data as Partial<GeneratedResult>;

  return {
    type:
      typeof payload?.type === "string"
        ? payload.type
        : tool === "image"
          ? "image"
          : "text",
    category: typeof payload?.category === "string" ? payload.category : tool,
    content: typeof payload?.content === "string" ? payload.content : undefined,
    preview: typeof payload?.preview === "string" ? payload.preview : undefined,
    code: typeof payload?.code === "string" ? payload.code : undefined,
    files: Array.isArray(payload?.files) ? payload.files : undefined,
    instructions:
      typeof payload?.instructions === "string"
        ? payload.instructions
        : undefined,
    projectName:
      typeof payload?.projectName === "string"
        ? payload.projectName
        : undefined,
    projectType:
      typeof payload?.projectType === "string"
        ? payload.projectType
        : undefined,
    prompt,
    version,
    modification,
    imageSettings: tool === "image" ? imageSettings : undefined,
  };
};

export const getCreativeToolLabel = (tool: CreativeTool) =>
  TOOL_LABELS[tool] ?? tool;

export const requestCreativePlan = async (
  tool: CreativeTool,
  prompt: string,
  modification?: string,
  options?: PlanOptions & { existingPlan?: GenerationPlan | null },
): Promise<GenerationPlan> => {
  if (
    !import.meta.env.VITE_SUPABASE_URL ||
    !import.meta.env.VITE_SUPABASE_PUBLISHABLE_KEY
  ) {
    throw new Error("Configuration Supabase manquante");
  }

  const { image } = options ?? {};

  const { data, error } = await supabase.functions.invoke("generate-content", {
    body: {
      prompt,
      category: tool,
      modification: modification?.trim() ? modification : undefined,
      mode: "plan",
      existingPlan: options?.existingPlan ?? undefined,
      imageSettings: tool === "image" ? image : undefined,
    },
  });

  if (error) {
    throw new Error(error.message);
  }

  const payload = data as { plan?: GenerationPlan } | GenerationPlan | null;
  const plan =
    payload && "plan" in (payload as Record<string, unknown>)
      ? (payload as { plan?: GenerationPlan }).plan
      : (payload as GenerationPlan | null);

  if (!plan) {
    throw new Error("Plan introuvable dans la r√©ponse");
  }

  return plan;
};
